{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EVA1st DNN_1.6.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNyZv-Ec52ot",
        "colab_type": "text"
      },
      "source": [
        "# **Import Libraries and modules**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m3w1Cw49Zkt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras    # intalled keras\n",
        "import keras             # import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eso6UHE080D4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np                                                        # import numpy for numerical calculation\n",
        "\n",
        "from keras.models import Sequential                                       # import keras` Sequential model which is a linear stack of layers.\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add         # importing : Dense - for fullconnected layers , Dropout : for dropout , Activation: activation function, \n",
        "                                                                          # Flatten : for converting n-dimensional array to 1-D array , Add : for adding layers\n",
        "\n",
        "from keras.layers import Convolution2D, MaxPooling2D,BatchNormalization\n",
        "from keras.utils import np_utils                                           # from keras.utils import np_utils which is a separate package (and a keras dependency - which doesn't get install with it)\n",
        "\n",
        "\n",
        "\n",
        "from keras.datasets import mnist                                          # from keras.datasets, importing mnist dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zByEi95J86RD",
        "colab_type": "text"
      },
      "source": [
        "### Load pre-shuffled MNIST data into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eRM0QWN83PV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()                 # Load mnist and make  tuple pair of train and test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a4Be72j8-ZC",
        "colab_type": "code",
        "outputId": "53066b9d-49c2-436a-ef98-52a18f32483e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        }
      },
      "source": [
        "print (X_train.shape)                                                  # printing dimension of X_train. Total 60k of 2-Dimension 28x28 image\n",
        "from matplotlib import pyplot as plt                                   # import pyplot as plt from matplotlib, used for plotting\n",
        "%matplotlib inline                                                     # matplotlib magic command to show static plot right below our code\n",
        "plt.imshow(X_train[0])                                                 # display first image in our training data"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f4d0a654a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbHjFwsWaoBR",
        "colab_type": "text"
      },
      "source": [
        "## Reshaping image because The Convolution2D layers in Keras are designed to work with 3 dimensions per example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkmprriw9AnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)      # reshaping 28x28x1 dimensions for all 60k images\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)         # reshaping 28x28x1 dimensions for all 10k images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SudCgN5dazGY",
        "colab_type": "text"
      },
      "source": [
        "## Change numpy array data types and Scaled\n",
        "Currently it has \"uint8\" i.e. Unsigned integer (0 to 255).\n",
        "\n",
        "**Scaled** ? Since we used Gradient Descent, for faster convergence we required number to be scaled."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2m4YS4E9CRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')                   # changed array’s data-type to float32\n",
        "X_test = X_test.astype('float32')                     # same as above\n",
        "\n",
        "# scale the pixel intensities down to the 0-1 range by dividing them by 255 which is the max value       \n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNyLlLLSbF1w",
        "colab_type": "text"
      },
      "source": [
        "## One-hot vector labels of target variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mn0vAYD9DvB",
        "colab_type": "code",
        "outputId": "e680570a-b733-44a3-9f6d-15021f2c118f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y_train[:10]                     # checking first 10 digits label (target variable)"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG8JiXR39FHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYlFRvKS9HMB",
        "colab_type": "code",
        "outputId": "1ec04236-8a95-4328-d1d8-1764b96cd9fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "Y_train[:10]                     # the first 10 class` array, compare the position of 1 (count starts from 0) in below and our y_train[:10] values. These two are same!!\n"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BH9yyNg1bQe_",
        "colab_type": "text"
      },
      "source": [
        "## Import google colab drive and user authentication"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gt8t4GwIEuL",
        "colab_type": "code",
        "outputId": "c45b53b3-dc60-4eb7-d8ed-c9ac8b7e34cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials \n",
        "\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiOaOjoxbp9W",
        "colab_type": "text"
      },
      "source": [
        "## Defining model\n",
        "\n",
        "Used the following:\n",
        "\n",
        "- Batchnormalization\n",
        "- Dropout\n",
        "- MaxPooling\n",
        "- 1x1 convolution\n",
        "- 3x3 kernel\n",
        "\n",
        "Also please note, we have structure model as\n",
        "- convolution block\n",
        "- transition block\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osKqT73Q9JJB",
        "colab_type": "code",
        "outputId": "4f3448a4-b2af-4c62-9653-21e23cd7461e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1157
        }
      },
      "source": [
        "from keras.layers import Activation                             # importing \"Activation\" MaxPooling2D \n",
        "model = Sequential()                                            # initiate keras` Sequential model \n",
        "\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu', use_bias=False,input_shape=(28,28,1)))    \n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(16, 3,3, use_bias=False, activation='relu'))                           \n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))                       \n",
        "model.add(Convolution2D(16, 3,3, use_bias=False, activation='relu'))                          \n",
        "\n",
        "\n",
        "model.add(MaxPooling2D((2, 2)))                                                                \n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(10, 1, use_bias=False, activation='relu'))   \n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(16, 3,3, use_bias=False, activation='relu'))                          \n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Convolution2D(16, 3,3, use_bias=False, activation='relu'))                         \n",
        "\n",
        "model.add(MaxPooling2D((2, 2)))                                                               \n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(10, 1, use_bias=False, activation='relu')) \n",
        "\n",
        "model.add(Convolution2D(10, 3,3, use_bias=False, activation='relu'))  \n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", use_bias=False, input_shape=(28, 28, 1...)`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), use_bias=False, activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), use_bias=False, activation=\"relu\")`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), use_bias=False, activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), use_bias=False, activation=\"relu\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_158 (Conv2D)          (None, 26, 26, 32)        288       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 26, 26, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_78 (Batc (None, 26, 26, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_159 (Conv2D)          (None, 24, 24, 16)        4608      \n",
            "_________________________________________________________________\n",
            "batch_normalization_79 (Batc (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_160 (Conv2D)          (None, 22, 22, 16)        2304      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_48 (MaxPooling (None, 11, 11, 16)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_80 (Batc (None, 11, 11, 16)        64        \n",
            "_________________________________________________________________\n",
            "conv2d_161 (Conv2D)          (None, 11, 11, 10)        160       \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 11, 11, 10)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_81 (Batc (None, 11, 11, 10)        40        \n",
            "_________________________________________________________________\n",
            "conv2d_162 (Conv2D)          (None, 9, 9, 16)          1440      \n",
            "_________________________________________________________________\n",
            "batch_normalization_82 (Batc (None, 9, 9, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 9, 9, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_163 (Conv2D)          (None, 7, 7, 16)          2304      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_49 (MaxPooling (None, 3, 3, 16)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_83 (Batc (None, 3, 3, 16)          64        \n",
            "_________________________________________________________________\n",
            "conv2d_164 (Conv2D)          (None, 3, 3, 10)          160       \n",
            "_________________________________________________________________\n",
            "conv2d_165 (Conv2D)          (None, 1, 1, 10)          900       \n",
            "_________________________________________________________________\n",
            "flatten_24 (Flatten)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_24 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 12,588\n",
            "Trainable params: 12,376\n",
            "Non-trainable params: 212\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), use_bias=False, activation=\"relu\")`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qOcU3v-bzCr",
        "colab_type": "text"
      },
      "source": [
        "## Configures the model for training.\n",
        "- loss as 'categorical_crossentropy' since we are dealing with multi-class classification\n",
        "- \"adam\" - Adaptive Moment Estimation one of the common/best gradient-based optimizer\n",
        "- \"accuracy\" as the model metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp6SuGrL9M3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# configure model with above parameters\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQoz8ATRcidQ",
        "colab_type": "text"
      },
      "source": [
        "## Callbacks for model monitor during training and saving weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1MJY9BfjvVe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import  ModelCheckpoint  # importing checkpoint\n",
        "\n",
        "filepath=\"/content/gdrive/My Drive/EVA_1.6_weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"                                  # filepath in google drive to save weights\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max',save_weights_only=True)    # checkpoint to monitor validation accuracy, and save which give max accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCUoiHR5cWfT",
        "colab_type": "text"
      },
      "source": [
        "### Fit the model on Training set\n",
        "batch_size=25 : sends 25 image in batch-wise and train model (feed-forward and backpropagation)\n",
        "10 number of epoch : One epoch is when an entire dataset is passed both forward and backward through the neural network only once.\n",
        "verbose as 1 : show progress bar of the training with details"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bl83jg2TkAXP",
        "colab_type": "code",
        "outputId": "e773355b-325d-4b53-9a07-a5af8fca97ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=25, nb_epoch=10, verbose=1,       # fit model with above notes along with checkpoint\n",
        "         validation_data=(X_test, Y_test),callbacks=[checkpoint])"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 53s 878us/step - loss: 0.3096 - acc: 0.9029 - val_loss: 0.0629 - val_acc: 0.9804\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.98040, saving model to /content/gdrive/My Drive/EVA_1.6_weights-improvement-01-0.98.hdf5\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 56s 927us/step - loss: 0.0906 - acc: 0.9718 - val_loss: 0.0436 - val_acc: 0.9865\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.98040 to 0.98650, saving model to /content/gdrive/My Drive/EVA_1.6_weights-improvement-02-0.99.hdf5\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 87s 1ms/step - loss: 0.0715 - acc: 0.9779 - val_loss: 0.0407 - val_acc: 0.9867\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.98650 to 0.98670, saving model to /content/gdrive/My Drive/EVA_1.6_weights-improvement-03-0.99.hdf5\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 88s 1ms/step - loss: 0.0628 - acc: 0.9811 - val_loss: 0.0334 - val_acc: 0.9892\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.98670 to 0.98920, saving model to /content/gdrive/My Drive/EVA_1.6_weights-improvement-04-0.99.hdf5\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 86s 1ms/step - loss: 0.0552 - acc: 0.9825 - val_loss: 0.0385 - val_acc: 0.9878\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.98920\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 88s 1ms/step - loss: 0.0523 - acc: 0.9834 - val_loss: 0.0314 - val_acc: 0.9897\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.98920 to 0.98970, saving model to /content/gdrive/My Drive/EVA_1.6_weights-improvement-06-0.99.hdf5\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 93s 2ms/step - loss: 0.0502 - acc: 0.9841 - val_loss: 0.0338 - val_acc: 0.9892\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.98970\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 121s 2ms/step - loss: 0.0480 - acc: 0.9849 - val_loss: 0.0316 - val_acc: 0.9899\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.98970 to 0.98990, saving model to /content/gdrive/My Drive/EVA_1.6_weights-improvement-08-0.99.hdf5\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 121s 2ms/step - loss: 0.0439 - acc: 0.9860 - val_loss: 0.0287 - val_acc: 0.9912\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.98990 to 0.99120, saving model to /content/gdrive/My Drive/EVA_1.6_weights-improvement-09-0.99.hdf5\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 119s 2ms/step - loss: 0.0441 - acc: 0.9859 - val_loss: 0.0256 - val_acc: 0.9922\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.99120 to 0.99220, saving model to /content/gdrive/My Drive/EVA_1.6_weights-improvement-10-0.99.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4d08d9f320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaduSJC_r1gO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1530
        },
        "outputId": "1625f1ca-05f3-4f7b-8705-8b4d65ad12f8"
      },
      "source": [
        "model.load_weights('/content/gdrive/My Drive/EVA_1.6_weights-improvement-10-0.99.hdf5')  # load weight which give 99.22 accuracy in above training\n",
        "\n",
        "model.fit(X_train, Y_train, batch_size=25, nb_epoch=20, verbose=1,                       # fit the model and train for 20 epoch again\n",
        "         validation_data=(X_test, Y_test),callbacks=[checkpoint])"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "   75/60000 [..............................] - ETA: 1:55 - loss: 0.1059 - acc: 0.9733"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 123s 2ms/step - loss: 0.0434 - acc: 0.9860 - val_loss: 0.0332 - val_acc: 0.9905\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.99220\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 121s 2ms/step - loss: 0.0407 - acc: 0.9872 - val_loss: 0.0261 - val_acc: 0.9927\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.99220 to 0.99270, saving model to /content/gdrive/My Drive/EVA_1.6_weights-improvement-02-0.99.hdf5\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 122s 2ms/step - loss: 0.0406 - acc: 0.9878 - val_loss: 0.0274 - val_acc: 0.9927\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.99270 to 0.99270, saving model to /content/gdrive/My Drive/EVA_1.6_weights-improvement-03-0.99.hdf5\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 122s 2ms/step - loss: 0.0397 - acc: 0.9868 - val_loss: 0.0262 - val_acc: 0.9923\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.99270\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 123s 2ms/step - loss: 0.0363 - acc: 0.9885 - val_loss: 0.0293 - val_acc: 0.9909\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.99270\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 118s 2ms/step - loss: 0.0375 - acc: 0.9877 - val_loss: 0.0282 - val_acc: 0.9921\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.99270\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 123s 2ms/step - loss: 0.0363 - acc: 0.9881 - val_loss: 0.0253 - val_acc: 0.9925\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.99270\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 114s 2ms/step - loss: 0.0353 - acc: 0.9884 - val_loss: 0.0258 - val_acc: 0.9927\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.99270 to 0.99270, saving model to /content/gdrive/My Drive/EVA_1.6_weights-improvement-08-0.99.hdf5\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 84s 1ms/step - loss: 0.0347 - acc: 0.9887 - val_loss: 0.0256 - val_acc: 0.9930\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.99270 to 0.99300, saving model to /content/gdrive/My Drive/EVA_1.6_weights-improvement-09-0.99.hdf5\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 51s 851us/step - loss: 0.0347 - acc: 0.9890 - val_loss: 0.0253 - val_acc: 0.9929\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.99300\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 85s 1ms/step - loss: 0.0342 - acc: 0.9889 - val_loss: 0.0269 - val_acc: 0.9925\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.99300\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 84s 1ms/step - loss: 0.0324 - acc: 0.9898 - val_loss: 0.0302 - val_acc: 0.9913\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.99300\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0336 - acc: 0.9896 - val_loss: 0.0268 - val_acc: 0.9915\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.99300\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 83s 1ms/step - loss: 0.0331 - acc: 0.9894 - val_loss: 0.0262 - val_acc: 0.9918\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.99300\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 101s 2ms/step - loss: 0.0325 - acc: 0.9897 - val_loss: 0.0275 - val_acc: 0.9921\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.99300\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 122s 2ms/step - loss: 0.0306 - acc: 0.9904 - val_loss: 0.0269 - val_acc: 0.9923\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.99300\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 122s 2ms/step - loss: 0.0309 - acc: 0.9900 - val_loss: 0.0260 - val_acc: 0.9922\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.99300\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 123s 2ms/step - loss: 0.0300 - acc: 0.9906 - val_loss: 0.0276 - val_acc: 0.9918\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.99300\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 122s 2ms/step - loss: 0.0296 - acc: 0.9901 - val_loss: 0.0248 - val_acc: 0.9923\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.99300\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 116s 2ms/step - loss: 0.0302 - acc: 0.9905 - val_loss: 0.0275 - val_acc: 0.9920\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.99300\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4d0830dba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSQuQwWQr1c4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2952
        },
        "outputId": "36a37555-d17a-421a-d0c9-f304a788b9b1"
      },
      "source": [
        "model.load_weights('/content/gdrive/My Drive/EVA_1.6_weights-improvement-09-0.99.hdf5')    # load weight which give 99.3 accuracy in above training\n",
        "\n",
        "\n",
        "model.fit(X_train, Y_train, batch_size=25, nb_epoch=40, verbose=1,                         # fit the model and train for 40 epoch again\n",
        "         validation_data=(X_test, Y_test),callbacks=[checkpoint])"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/40\n",
            "   75/60000 [..............................] - ETA: 2:22 - loss: 0.0029 - acc: 1.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 126s 2ms/step - loss: 0.0360 - acc: 0.9886 - val_loss: 0.0242 - val_acc: 0.9928\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.99300\n",
            "Epoch 2/40\n",
            "60000/60000 [==============================] - 125s 2ms/step - loss: 0.0332 - acc: 0.9894 - val_loss: 0.0236 - val_acc: 0.9930\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.99300\n",
            "Epoch 3/40\n",
            "60000/60000 [==============================] - 125s 2ms/step - loss: 0.0330 - acc: 0.9891 - val_loss: 0.0251 - val_acc: 0.9920\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.99300\n",
            "Epoch 4/40\n",
            "60000/60000 [==============================] - 125s 2ms/step - loss: 0.0342 - acc: 0.9893 - val_loss: 0.0267 - val_acc: 0.9920\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.99300\n",
            "Epoch 5/40\n",
            "60000/60000 [==============================] - 124s 2ms/step - loss: 0.0308 - acc: 0.9899 - val_loss: 0.0261 - val_acc: 0.9917\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.99300\n",
            "Epoch 6/40\n",
            "60000/60000 [==============================] - 125s 2ms/step - loss: 0.0300 - acc: 0.9903 - val_loss: 0.0257 - val_acc: 0.9924\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.99300\n",
            "Epoch 7/40\n",
            "60000/60000 [==============================] - 124s 2ms/step - loss: 0.0314 - acc: 0.9895 - val_loss: 0.0269 - val_acc: 0.9923\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.99300\n",
            "Epoch 8/40\n",
            "60000/60000 [==============================] - 123s 2ms/step - loss: 0.0303 - acc: 0.9905 - val_loss: 0.0334 - val_acc: 0.9912\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.99300\n",
            "Epoch 9/40\n",
            "60000/60000 [==============================] - 127s 2ms/step - loss: 0.0300 - acc: 0.9903 - val_loss: 0.0247 - val_acc: 0.9925\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.99300\n",
            "Epoch 10/40\n",
            "60000/60000 [==============================] - 128s 2ms/step - loss: 0.0290 - acc: 0.9906 - val_loss: 0.0250 - val_acc: 0.9922\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.99300\n",
            "Epoch 11/40\n",
            "60000/60000 [==============================] - 91s 2ms/step - loss: 0.0302 - acc: 0.9902 - val_loss: 0.0273 - val_acc: 0.9917\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.99300\n",
            "Epoch 12/40\n",
            "60000/60000 [==============================] - 85s 1ms/step - loss: 0.0307 - acc: 0.9901 - val_loss: 0.0258 - val_acc: 0.9923\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.99300\n",
            "Epoch 13/40\n",
            "60000/60000 [==============================] - 83s 1ms/step - loss: 0.0295 - acc: 0.9904 - val_loss: 0.0243 - val_acc: 0.9936\n",
            "\n",
            "Epoch 00013: val_acc improved from 0.99300 to 0.99360, saving model to /content/gdrive/My Drive/EVA_1.6_weights-improvement-13-0.99.hdf5\n",
            "Epoch 14/40\n",
            "60000/60000 [==============================] - 83s 1ms/step - loss: 0.0293 - acc: 0.9905 - val_loss: 0.0267 - val_acc: 0.9924\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.99360\n",
            "Epoch 15/40\n",
            "60000/60000 [==============================] - 83s 1ms/step - loss: 0.0284 - acc: 0.9907 - val_loss: 0.0259 - val_acc: 0.9928\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.99360\n",
            "Epoch 16/40\n",
            "60000/60000 [==============================] - 74s 1ms/step - loss: 0.0290 - acc: 0.9904 - val_loss: 0.0249 - val_acc: 0.9915\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.99360\n",
            "Epoch 17/40\n",
            "60000/60000 [==============================] - 48s 796us/step - loss: 0.0290 - acc: 0.9902 - val_loss: 0.0266 - val_acc: 0.9925\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.99360\n",
            "Epoch 18/40\n",
            "60000/60000 [==============================] - 48s 800us/step - loss: 0.0288 - acc: 0.9906 - val_loss: 0.0269 - val_acc: 0.9925\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.99360\n",
            "Epoch 19/40\n",
            "60000/60000 [==============================] - 73s 1ms/step - loss: 0.0281 - acc: 0.9910 - val_loss: 0.0261 - val_acc: 0.9920\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.99360\n",
            "Epoch 20/40\n",
            "60000/60000 [==============================] - 83s 1ms/step - loss: 0.0275 - acc: 0.9914 - val_loss: 0.0241 - val_acc: 0.9923\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.99360\n",
            "Epoch 21/40\n",
            "60000/60000 [==============================] - 83s 1ms/step - loss: 0.0258 - acc: 0.9918 - val_loss: 0.0252 - val_acc: 0.9920\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.99360\n",
            "Epoch 22/40\n",
            "60000/60000 [==============================] - 76s 1ms/step - loss: 0.0264 - acc: 0.9908 - val_loss: 0.0229 - val_acc: 0.9932\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.99360\n",
            "Epoch 23/40\n",
            "60000/60000 [==============================] - 81s 1ms/step - loss: 0.0287 - acc: 0.9907 - val_loss: 0.0226 - val_acc: 0.9931\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.99360\n",
            "Epoch 24/40\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0271 - acc: 0.9911 - val_loss: 0.0254 - val_acc: 0.9924\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.99360\n",
            "Epoch 25/40\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0258 - acc: 0.9917 - val_loss: 0.0268 - val_acc: 0.9923\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.99360\n",
            "Epoch 26/40\n",
            "60000/60000 [==============================] - 68s 1ms/step - loss: 0.0263 - acc: 0.9912 - val_loss: 0.0250 - val_acc: 0.9931\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.99360\n",
            "Epoch 27/40\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0261 - acc: 0.9918 - val_loss: 0.0219 - val_acc: 0.9931\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.99360\n",
            "Epoch 28/40\n",
            "60000/60000 [==============================] - 83s 1ms/step - loss: 0.0249 - acc: 0.9918 - val_loss: 0.0242 - val_acc: 0.9935\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.99360\n",
            "Epoch 29/40\n",
            "60000/60000 [==============================] - 78s 1ms/step - loss: 0.0252 - acc: 0.9917 - val_loss: 0.0246 - val_acc: 0.9928\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.99360\n",
            "Epoch 30/40\n",
            "60000/60000 [==============================] - 78s 1ms/step - loss: 0.0267 - acc: 0.9909 - val_loss: 0.0269 - val_acc: 0.9930\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.99360\n",
            "Epoch 31/40\n",
            "60000/60000 [==============================] - 78s 1ms/step - loss: 0.0257 - acc: 0.9917 - val_loss: 0.0233 - val_acc: 0.9929\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.99360\n",
            "Epoch 32/40\n",
            "60000/60000 [==============================] - 81s 1ms/step - loss: 0.0247 - acc: 0.9917 - val_loss: 0.0231 - val_acc: 0.9932\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.99360\n",
            "Epoch 33/40\n",
            "60000/60000 [==============================] - 76s 1ms/step - loss: 0.0254 - acc: 0.9915 - val_loss: 0.0223 - val_acc: 0.9933\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.99360\n",
            "Epoch 34/40\n",
            "60000/60000 [==============================] - 81s 1ms/step - loss: 0.0244 - acc: 0.9920 - val_loss: 0.0241 - val_acc: 0.9930\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.99360\n",
            "Epoch 35/40\n",
            "60000/60000 [==============================] - 80s 1ms/step - loss: 0.0255 - acc: 0.9919 - val_loss: 0.0239 - val_acc: 0.9932\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.99360\n",
            "Epoch 36/40\n",
            "60000/60000 [==============================] - 81s 1ms/step - loss: 0.0247 - acc: 0.9918 - val_loss: 0.0249 - val_acc: 0.9925\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.99360\n",
            "Epoch 37/40\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0241 - acc: 0.9922 - val_loss: 0.0242 - val_acc: 0.9923\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.99360\n",
            "Epoch 38/40\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0245 - acc: 0.9919 - val_loss: 0.0242 - val_acc: 0.9940\n",
            "\n",
            "Epoch 00038: val_acc improved from 0.99360 to 0.99400, saving model to /content/gdrive/My Drive/EVA_1.6_weights-improvement-38-0.99.hdf5\n",
            "Epoch 39/40\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0226 - acc: 0.9926 - val_loss: 0.0240 - val_acc: 0.9925\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.99400\n",
            "Epoch 40/40\n",
            "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0228 - acc: 0.9923 - val_loss: 0.0258 - val_acc: 0.9926\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.99400\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4d0827edd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKZwoDqkjaVD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "outputId": "cc0722fb-22b3-4d62-e25b-82276d9377e5"
      },
      "source": [
        "model.load_weights('/content/gdrive/My Drive/EVA_1.6_weights-improvement-38-0.99.hdf5')    # load weight which give 99.4 accuracy in above training\n",
        "\n",
        "\n",
        "model.fit(X_train, Y_train, batch_size=25, nb_epoch=10, verbose=1,                         # fit the model and train for 10 epoch again\n",
        "         validation_data=(X_test, Y_test),callbacks=[checkpoint])"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "  250/60000 [..............................] - ETA: 45s - loss: 0.0322 - acc: 0.9840"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 49s 809us/step - loss: 0.0242 - acc: 0.9921 - val_loss: 0.0233 - val_acc: 0.9926\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.99400\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 49s 813us/step - loss: 0.0241 - acc: 0.9922 - val_loss: 0.0245 - val_acc: 0.9929\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.99400\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 49s 814us/step - loss: 0.0228 - acc: 0.9923 - val_loss: 0.0226 - val_acc: 0.9941\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.99400 to 0.99410, saving model to /content/gdrive/My Drive/EVA_1.6_weights-improvement-03-0.99.hdf5\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 48s 805us/step - loss: 0.0233 - acc: 0.9927 - val_loss: 0.0253 - val_acc: 0.9926\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.99410\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 48s 802us/step - loss: 0.0240 - acc: 0.9922 - val_loss: 0.0228 - val_acc: 0.9939\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.99410\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 48s 800us/step - loss: 0.0232 - acc: 0.9928 - val_loss: 0.0244 - val_acc: 0.9936\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.99410\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 48s 798us/step - loss: 0.0227 - acc: 0.9923 - val_loss: 0.0237 - val_acc: 0.9936\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.99410\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 48s 802us/step - loss: 0.0240 - acc: 0.9920 - val_loss: 0.0271 - val_acc: 0.9917\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.99410\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 49s 811us/step - loss: 0.0216 - acc: 0.9928 - val_loss: 0.0246 - val_acc: 0.9932\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.99410\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 48s 806us/step - loss: 0.0229 - acc: 0.9926 - val_loss: 0.0224 - val_acc: 0.9930\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.99410\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4d06a09e48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kjMwCLEdlS9",
        "colab_type": "text"
      },
      "source": [
        "## Model evaluation\n",
        "Please note that predict is a part of model evaluation. Only after we predict, one can used prediction value to evalute our metrics, say \"accuracy\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MazRJXlGkoxp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights('/content/gdrive/My Drive/EVA_1.6_weights-improvement-03-0.99.hdf5')    # load weight which give 99.41 validation accuracy in above training"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtsH-lLk-eLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)    # Use trained model and predict on test set , then finally score metrics. We have given \"accuracy\" as our metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkX8JMv79q9r",
        "colab_type": "code",
        "outputId": "c39c513d-4ca8-4078-d0f2-b840e6de5a96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(score)  # print validation score"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.02262122784848325, 0.9941]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCWoJkwE9suh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(X_test)   # used trained model to predict class"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym7iCFBm9uBs",
        "colab_type": "code",
        "outputId": "fd2adfb0-c32d-47a9-d183-ed0089261097",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        }
      },
      "source": [
        "print(y_pred[:9])   # first 9 prediction\n",
        "print(y_test[:9])    # actual 9 targel class"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.8394343e-09 1.8394343e-09 6.1321783e-09 1.6163167e-08 1.8394343e-09\n",
            "  1.8394343e-09 1.8394343e-09 9.9999988e-01 1.8394343e-09 1.5962836e-07]\n",
            " [4.3903731e-07 7.7913010e-06 9.9999142e-01 2.8926873e-08 2.3842969e-07\n",
            "  2.8926873e-08 2.8926873e-08 2.8926873e-08 2.8926873e-08 2.8926873e-08]\n",
            " [1.6051163e-06 9.9996603e-01 1.6051163e-06 1.6051163e-06 9.8222754e-06\n",
            "  2.1602802e-06 4.2789588e-06 9.6953709e-06 1.6051163e-06 1.6051163e-06]\n",
            " [9.9998915e-01 3.8215592e-08 3.8215592e-08 3.8215592e-08 6.5953209e-08\n",
            "  6.5411008e-08 2.0478833e-06 3.8215592e-08 2.2245818e-07 8.2861252e-06]\n",
            " [7.3233825e-10 7.3233825e-10 7.3233825e-10 7.3233825e-10 9.9999809e-01\n",
            "  7.3233825e-10 7.3233825e-10 7.3233825e-10 5.5439786e-09 1.8434835e-06]\n",
            " [1.0637756e-06 9.9996364e-01 1.7070030e-06 1.0637756e-06 5.3266244e-06\n",
            "  1.0637756e-06 1.5220249e-06 2.2494276e-05 1.0637756e-06 1.0637756e-06]\n",
            " [1.1131694e-09 1.2117336e-09 1.1131694e-09 1.1131694e-09 1.0000000e+00\n",
            "  1.1131694e-09 1.1131694e-09 4.7465250e-08 5.9833560e-09 3.3443975e-08]\n",
            " [7.4894764e-08 7.4894764e-08 5.3542540e-06 7.4894764e-08 1.7208574e-04\n",
            "  4.9918776e-07 7.4894764e-08 1.0730226e-07 1.5964999e-07 9.9982160e-01]\n",
            " [3.3309502e-07 3.3309502e-07 3.3309502e-07 3.3309502e-07 3.3309502e-07\n",
            "  9.2761344e-01 7.1641222e-02 3.3309502e-07 7.4295275e-04 3.3309502e-07]]\n",
            "[7 2 1 0 4 1 4 9 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ah_y85XXd_z7",
        "colab_type": "text"
      },
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT--y98_dr2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_dict = dict([(layer.name, layer) for layer in model.layers])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GY4Upv4dsUR",
        "colab_type": "code",
        "outputId": "cc4da10c-dc07-4e6a-9e01-9ba4ff833245",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 741
        }
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from keras import backend as K\n",
        "%matplotlib inline\n",
        "# util function to convert a tensor into a valid image\n",
        "def deprocess_image(x):\n",
        "    # normalize tensor: center on 0., ensure std is 0.1\n",
        "    x -= x.mean()\n",
        "    x /= (x.std() + 1e-5)\n",
        "    x *= 0.1\n",
        "\n",
        "    # clip to [0, 1]\n",
        "    x += 0.5\n",
        "    x = np.clip(x, 0, 1)\n",
        "\n",
        "    # convert to RGB array\n",
        "    x *= 255\n",
        "    #x = x.transpose((1, 2, 0))\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x\n",
        "\n",
        "def vis_img_in_filter(img = np.array(X_train[2]).reshape((1, 28, 28, 1)).astype(np.float64), \n",
        "                      layer_name = 'conv2d_159'):\n",
        "    layer_output = layer_dict[layer_name].output\n",
        "    img_ascs = list()\n",
        "    for filter_index in range(layer_output.shape[3]):\n",
        "        # build a loss function that maximizes the activation\n",
        "        # of the nth filter of the layer considered\n",
        "        loss = K.mean(layer_output[:, :, :, filter_index])\n",
        "\n",
        "        # compute the gradient of the input picture wrt this loss\n",
        "        grads = K.gradients(loss, model.input)[0]\n",
        "\n",
        "        # normalization trick: we normalize the gradient\n",
        "        grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
        "\n",
        "        # this function returns the loss and grads given the input picture\n",
        "        iterate = K.function([model.input], [loss, grads])\n",
        "\n",
        "        # step size for gradient ascent\n",
        "        step = 5.\n",
        "\n",
        "        img_asc = np.array(img)\n",
        "        # run gradient ascent for 20 steps\n",
        "        for i in range(20):\n",
        "            loss_value, grads_value = iterate([img_asc])\n",
        "            img_asc += grads_value * step\n",
        "\n",
        "        img_asc = img_asc[0]\n",
        "        img_ascs.append(deprocess_image(img_asc).reshape((28, 28)))\n",
        "        \n",
        "    if layer_output.shape[3] >= 35:\n",
        "        plot_x, plot_y = 6, 6\n",
        "    elif layer_output.shape[3] >= 23:\n",
        "        plot_x, plot_y = 4, 6\n",
        "    elif layer_output.shape[3] >= 11:\n",
        "        plot_x, plot_y = 2, 6\n",
        "    else:\n",
        "        plot_x, plot_y = 1, 2\n",
        "    fig, ax = plt.subplots(plot_x, plot_y, figsize = (12, 12))\n",
        "    ax[0, 0].imshow(img.reshape((28, 28)), cmap = 'gray')\n",
        "    ax[0, 0].set_title('Input image')\n",
        "    fig.suptitle('Input image and %s filters' % (layer_name,))\n",
        "    fig.tight_layout(pad = 0.3, rect = [0, 0, 0.9, 0.9])\n",
        "    for (x, y) in [(i, j) for i in range(plot_x) for j in range(plot_y)]:\n",
        "        if x == 0 and y == 0:\n",
        "            continue\n",
        "        ax[x, y].imshow(img_ascs[x * plot_y + y - 1], cmap = 'gray')\n",
        "        ax[x, y].set_title('filter %d' % (x * plot_y + y - 1))\n",
        "\n",
        "vis_img_in_filter()"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAwoAAALUCAYAAACre8XKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYdkjTsnwmgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 864x864 with 12 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tvptcn8dxvp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}